name: PollPulse TN Daily Pipeline

on:
  # Run daily at 6:00 AM UTC (11:30 AM IST)
  schedule:
    - cron: '0 6 * * *'
  
  # Allow manual trigger
  workflow_dispatch:
    inputs:
      run_scrapers:
        description: 'Run scrapers (YouTube + News)'
        required: false
        default: true
        type: boolean
      run_processor:
        description: 'Run sentiment processor'
        required: false
        default: true
        type: boolean
      max_videos:
        description: 'Max videos to scrape per alliance'
        required: false
        default: '5'
        type: string

env:
  PYTHON_VERSION: '3.11'

jobs:
  # ==================================================
  # Job 1: Run YouTube Scrapers (Discover + Scrape)
  # ==================================================
  scrape-youtube:
    name: Scrape YouTube Content
    runs-on: ubuntu-latest
    environment: supabase
    if: |
      github.event_name == 'schedule' || 
      github.event.inputs.run_scrapers != false
    
    env:
      SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
      SUPABASE_KEY: ${{ secrets.SUPABASE_KEY }}
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
      
      - name: Verify Supabase credentials
        env:
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_KEY: ${{ secrets.SUPABASE_KEY }}
        run: |
          echo "Checking Supabase credentials..."
          echo "SUPABASE_URL length: ${#SUPABASE_URL}"
          echo "SUPABASE_KEY length: ${#SUPABASE_KEY}"
          
          if [ -z "$SUPABASE_URL" ] || [ -z "$SUPABASE_KEY" ]; then
            echo "ERROR: SUPABASE_URL or SUPABASE_KEY not set!"
            echo ""
            echo "To fix this:"
            echo "1. Go to your repository Settings → Secrets and variables → Actions"
            echo "2. Add secrets named SUPABASE_URL and SUPABASE_KEY:"
            echo "   Option A: Repository secrets (available to all workflows)"
            echo "   Option B: Environment secrets under 'supabase' environment"
            echo "3. Make sure the workflow references 'environment: supabase' if using environment secrets"
            echo "4. Re-run this workflow"
            exit 1
          else
            echo "[OK] Supabase credentials are set"
            echo "  URL: ${SUPABASE_URL:0:30}..."
            echo "  Key: ${SUPABASE_KEY:0:20}..."
          fi
      
      - name: Run YouTube Scraper
        run: |
          echo "Discovering and scraping YouTube videos..."
          echo "This will discover videos and scrape comments/transcripts..."
          python src/scraper.py
        env:
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_KEY: ${{ secrets.SUPABASE_KEY }}
          MAX_VIDEOS_PER_ALLIANCE: ${{ github.event.inputs.max_videos || '5' }}
        timeout-minutes: 30
      
      - name: Upload scrape logs
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: youtube-scrape-logs
          path: logs/
          retention-days: 7

  # ==================================================
  # Job 2: Run News Scrapers
  # ==================================================
  scrape-news:
    name: Scrape News Headlines
    runs-on: ubuntu-latest
    environment: supabase
    if: |
      github.event_name == 'schedule' || 
      github.event.inputs.run_scrapers != false
    
    env:
      SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
      SUPABASE_KEY: ${{ secrets.SUPABASE_KEY }}
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
      
      - name: Verify Supabase credentials
        env:
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_KEY: ${{ secrets.SUPABASE_KEY }}
        run: |
          echo "Checking Supabase credentials..."
          echo "SUPABASE_URL length: ${#SUPABASE_URL}"
          echo "SUPABASE_KEY length: ${#SUPABASE_KEY}"
          
          if [ -z "$SUPABASE_URL" ] || [ -z "$SUPABASE_KEY" ]; then
            echo "ERROR: SUPABASE_URL or SUPABASE_KEY not set!"
            echo ""
            echo "To fix this:"
            echo "1. Go to your repository Settings → Secrets and variables → Actions"
            echo "2. Add secrets named SUPABASE_URL and SUPABASE_KEY:"
            echo "   Option A: Repository secrets (available to all workflows)"
            echo "   Option B: Environment secrets under 'supabase' environment"
            echo "3. Make sure the workflow references 'environment: supabase' if using environment secrets"
            echo "4. Re-run this workflow"
            exit 1
          else
            echo "[OK] Supabase credentials are set"
            echo "  URL: ${SUPABASE_URL:0:30}..."
            echo "  Key: ${SUPABASE_KEY:0:20}..."
          fi
      
      - name: Run News Scraper
        run: |
          echo "Scraping news headlines from Daily Thanthi..."
          python src/news_scraper.py
        env:
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_KEY: ${{ secrets.SUPABASE_KEY }}
        timeout-minutes: 15
      
      - name: Upload news scrape logs
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: news-scrape-logs
          path: logs/
          retention-days: 7

  # ==================================================
  # Job 3: Run Sentiment Processor
  # ==================================================
  process-sentiment:
    name: Process Sentiment Analysis
    runs-on: ubuntu-latest
    environment: supabase
    needs: [scrape-youtube, scrape-news]
    if: |
      always() && 
      (github.event.inputs.run_processor != false) &&
      (needs.scrape-youtube.result == 'success' || needs.scrape-news.result == 'success')
    
    env:
      SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
      SUPABASE_KEY: ${{ secrets.SUPABASE_KEY }}
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
      
      - name: Verify Supabase credentials
        env:
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_KEY: ${{ secrets.SUPABASE_KEY }}
        run: |
          echo "Checking Supabase credentials..."
          echo "SUPABASE_URL length: ${#SUPABASE_URL}"
          echo "SUPABASE_KEY length: ${#SUPABASE_KEY}"
          
          if [ -z "$SUPABASE_URL" ] || [ -z "$SUPABASE_KEY" ]; then
            echo "ERROR: SUPABASE_URL or SUPABASE_KEY not set!"
            echo ""
            echo "To fix this:"
            echo "1. Go to your repository Settings → Secrets and variables → Actions"
            echo "2. Add secrets named SUPABASE_URL and SUPABASE_KEY:"
            echo "   Option A: Repository secrets (available to all workflows)"
            echo "   Option B: Environment secrets under 'supabase' environment"
            echo "3. Make sure the workflow references 'environment: supabase' if using environment secrets"
            echo "4. Re-run this workflow"
            exit 1
          else
            echo "[OK] Supabase credentials are set"
            echo "  URL: ${SUPABASE_URL:0:30}..."
            echo "  Key: ${SUPABASE_KEY:0:20}..."
          fi
      
      - name: Download ML Model (cached)
        run: |
          echo "Pre-downloading sentiment model..."
          python -c "from transformers import pipeline; pipeline('sentiment-analysis', model='cardiffnlp/twitter-xlm-roberta-base-sentiment')"
      
      - name: Run Sentiment Processor
        run: |
          echo "Processing sentiment analysis..."
          # Run processor for a limited time (process available jobs)
          timeout 1800 python src/processor.py || true
        timeout-minutes: 35
        env:
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_KEY: ${{ secrets.SUPABASE_KEY }}
          ENABLE_DEDUPLICATION: 'true'
          ENABLE_DLQ: 'true'
          ENABLE_METRICS: 'true'
          ENABLE_OUTLIER_CAP: 'true'
          ENABLE_ENGAGEMENT_WEIGHTING: 'true'
          ENABLE_PROBABILITY_SCORING: 'true'
      
      - name: Upload processor logs
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: processor-logs
          path: logs/
          retention-days: 7

  # ==================================================
  # Job 4: Generate Daily Report
  # ==================================================
  generate-report:
    name: Generate Daily Report
    runs-on: ubuntu-latest
    environment: supabase
    needs: [process-sentiment]
    if: always() && needs.process-sentiment.result == 'success'
    
    env:
      SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
      SUPABASE_KEY: ${{ secrets.SUPABASE_KEY }}
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
      
      - name: Verify Supabase credentials
        env:
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_KEY: ${{ secrets.SUPABASE_KEY }}
        run: |
          echo "Checking Supabase credentials..."
          echo "SUPABASE_URL length: ${#SUPABASE_URL}"
          echo "SUPABASE_KEY length: ${#SUPABASE_KEY}"
          
          if [ -z "$SUPABASE_URL" ] || [ -z "$SUPABASE_KEY" ]; then
            echo "ERROR: SUPABASE_URL or SUPABASE_KEY not set!"
            echo ""
            echo "To fix this:"
            echo "1. Go to your repository Settings → Secrets and variables → Actions"
            echo "2. Add secrets named SUPABASE_URL and SUPABASE_KEY:"
            echo "   Option A: Repository secrets (available to all workflows)"
            echo "   Option B: Environment secrets under 'supabase' environment"
            echo "3. Make sure the workflow references 'environment: supabase' if using environment secrets"
            echo "4. Re-run this workflow"
            exit 1
          else
            echo "[OK] Supabase credentials are set"
            echo "  URL: ${SUPABASE_URL:0:30}..."
            echo "  Key: ${SUPABASE_KEY:0:20}..."
          fi
      
      - name: Generate Summary Report
        run: |
          echo "Generating daily summary..."
          python << 'EOF'
          import json
          from datetime import datetime
          from src.infra.client import get_supabase_client

          client = get_supabase_client()
          if not client:
              print("Could not connect to Supabase")
              exit(1)

          # Fetch summary
          result = client.table('constituency_predictions').select('*').execute()
          predictions = result.data or []

          # Calculate stats
          alliance_stats = {}
          for p in predictions:
              alliance = p['alliance']
              if alliance not in alliance_stats:
                  alliance_stats[alliance] = {'count': 0, 'total_sentiment': 0, 'sources': 0}
              alliance_stats[alliance]['count'] += 1
              alliance_stats[alliance]['total_sentiment'] += p['sentiment_score']
              alliance_stats[alliance]['sources'] += p.get('source_count', 0)

          print("\n" + "=" * 60)
          print(f"POLLPULSE TN - DAILY REPORT ({datetime.now().strftime('%Y-%m-%d')})")
          print("=" * 60)
          print(f"\nTotal Predictions: {len(predictions)}")
          print(f"Unique Constituencies: {len(set(p['constituency_name'] for p in predictions))}")
          print("\nAlliance Summary:")
          for alliance, stats in sorted(alliance_stats.items(), key=lambda x: -x[1]['count']):
              avg_sentiment = stats['total_sentiment'] / stats['count'] if stats['count'] > 0 else 0
              print(f"  {alliance:20s}: {stats['count']:3d} predictions | Avg Sentiment: {avg_sentiment:+.2f} | Sources: {stats['sources']}")
          print("=" * 60)
          EOF
        env:
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_KEY: ${{ secrets.SUPABASE_KEY }}

  # ==================================================
  # Job 5: Notify on Failure
  # ==================================================
  notify-failure:
    name: Notify on Failure
    runs-on: ubuntu-latest
    needs: [scrape-youtube, scrape-news, process-sentiment]
    if: failure()
    
    steps:
      - name: Create failure summary
        run: |
          echo "## Pipeline Failed" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "One or more jobs in the PollPulse TN pipeline failed." >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Jobs Status:**" >> $GITHUB_STEP_SUMMARY
          echo "- YouTube Scraper: ${{ needs.scrape-youtube.result }}" >> $GITHUB_STEP_SUMMARY
          echo "- News Scraper: ${{ needs.scrape-news.result }}" >> $GITHUB_STEP_SUMMARY
          echo "- Sentiment Processor: ${{ needs.process-sentiment.result }}" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "Check the workflow logs for details." >> $GITHUB_STEP_SUMMARY
